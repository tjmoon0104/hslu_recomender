{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c512d9ce-ec05-4e7f-b027-2d65888c1c63",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "\n",
    "from recommender.data_processing import map_column, get_context\n",
    "from recommender.training import Dataset\n",
    "from recommender.models import Recommender\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed6711a6-5104-41af-87e5-610ec2e1eabe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df.sort_values(by='ts_listen', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d5662fa-0d69-4a53-bcca-a17b704a4a39",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample_id = np.sort(df.user_id.unique())[:1000].tolist()\n",
    "sample_data = copy(df.query(f\"user_id=={sample_id}\"))\n",
    "sample_data, sample_mapping, sample_inverse_mapping = map_column(sample_data, col_name=\"media_id\")\n",
    "\n",
    "gb = sample_data.groupby(by=\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78ad33f4-41fa-4979-9aa6-10850ce861d4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_list, test_list = [], []\n",
    "\n",
    "# Sampling based on user and split 80:20 by sorted 'ts_listen'\n",
    "\n",
    "for group in list(gb.groups):\n",
    "    df_group = gb.get_group(group)\n",
    "    train_group, test_group = train_test_split(df_group, test_size=0.2, random_state=0, shuffle=False)\n",
    "    train_list.append(train_group)\n",
    "    test_list.append(test_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2450c021-7710-4e14-b99a-bbb3f2b3662e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.concat(train_list)\n",
    "test = pd.concat(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a670a90d-2eed-4704-a501-66c9340d1d90",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_train = copy(train.query(\"is_listened==1\"))\n",
    "grp_by_train = data_train.groupby(by=\"user_id\")\n",
    "groups = list(grp_by_train.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2164f30-45fe-47f1-ac58-5721c5e06f22",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "history_size = 120\n",
    "\n",
    "train_data = Dataset(\n",
    "    groups=groups,\n",
    "    grp_by=grp_by_train,\n",
    "    split=\"train\",\n",
    "    history_size=history_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b38b393-b300-41cb-b647-f7f4eee0a2fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f78f2152-612a-43b5-a7fe-fb937ecca4d5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "log_dir = \"recommender_logs\"\n",
    "model_dir = \"recommender_models\"\n",
    "# model_dir = \"recommender_models_cpu\"\n",
    "\n",
    "model = Recommender(\n",
    "    vocab_size=len(sample_mapping) + 2,\n",
    "    lr=1e-4,\n",
    "    dropout=0.3,\n",
    ")\n",
    "\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir=log_dir,\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"valid_loss\",\n",
    "    mode=\"min\",\n",
    "    dirpath=model_dir,\n",
    "    filename=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7865236f-633e-4cdc-b9e3-b74bc1aee272",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/moon/miniforge3/envs/python39cpu/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1789: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "/Users/moon/miniforge3/envs/python39cpu/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /Users/moon/HSLU/RecommenderSystem/recommender_models exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name                | Type               | Params\n",
      "-----------------------------------------------------------\n",
      "0 | item_embeddings     | Embedding          | 23.6 M\n",
      "1 | input_pos_embedding | Embedding          | 65.5 K\n",
      "2 | encoder             | TransformerEncoder | 3.6 M \n",
      "3 | linear_out          | Linear             | 23.8 M\n",
      "4 | do                  | Dropout            | 0     \n",
      "-----------------------------------------------------------\n",
      "51.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "51.1 M    Total params\n",
      "204.309   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5fd3d06089054cfe80fa6f626f061ecf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moon/miniforge3/envs/python39cpu/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/moon/miniforge3/envs/python39cpu/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/moon/miniforge3/envs/python39cpu/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1892: PossibleUserWarning: The number of training batches (32) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "88ca707253304732b905c2e699c8c85f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moon/miniforge3/envs/python39cpu/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:653: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=epochs,\n",
    "    logger=logger,\n",
    "    accelerator='gpu',\n",
    "    devices=1,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_loader, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f63c864f-ff02-4e94-8f32-33e916729f3c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1386: UserWarning: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "  rank_zero_warn(\n",
      "Restoring states from the checkpoint path at /home/studio-lab-user/sagemaker-studiolab-notebooks/recommender_models/epoch=91-step=368.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /home/studio-lab-user/sagemaker-studiolab-notebooks/recommender_models/epoch=91-step=368.ckpt\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec5e8d53cd9457491845c5bd72e721f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy                 0.0\n",
      "        test_loss           11.085309982299805\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "{'val_loss': 11.085309982299805, 'best_model_path': '/home/studio-lab-user/sagemaker-studiolab-notebooks/recommender_models/epoch=91-step=368.ckpt'}\n"
     ]
    }
   ],
   "source": [
    "result_val = trainer.test(dataloaders=val_loader)\n",
    "\n",
    "output_json = {\n",
    "    \"val_loss\": result_val[0][\"test_loss\"],\n",
    "    \"best_model_path\": checkpoint_callback.best_model_path,\n",
    "}\n",
    "\n",
    "print(output_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8837b246-dc15-460c-a755-7b1e881a844a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "PAD = 0\n",
    "MASK = 1\n",
    "\n",
    "ids = [PAD] * (120 - 1 - 1) + [mapping[206493]] + [MASK]\n",
    "\n",
    "src = torch.tensor(ids, dtype=torch.long).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2d0ceb1-1f9e-4a27-b7de-cc19eda7c404",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    prediction = model(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0372506d-dde5-4d6c-b58b-61d5b0092b4e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "masked_pred = prediction[0, -1].numpy()\n",
    "\n",
    "sorted_predicted_ids = np.argsort(masked_pred).tolist()[::-1]\n",
    "\n",
    "sorted_predicted_ids = [a for a in sorted_predicted_ids if a not in ids]\n",
    "\n",
    "# return [idx_to_movie[a] for a in sorted_predicted_ids[:30] if a in idx_to_movie]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c3875a0-67da-48d9-a565-58cd855c65b4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'map_column' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_99/1756759025.py\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmapping\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minverse_mapping\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmap_column\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcol_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"media_id\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'map_column' is not defined"
     ]
    }
   ],
   "source": [
    "data, mapping, inverse_mapping = map_column(data, col_name=\"media_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf320510-0a0b-4895-a4a3-f8bc4fbfa82f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mapping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_99/2521852306.py\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmapping\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m206493\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'mapping' is not defined"
     ]
    }
   ],
   "source": [
    "mapping[206493]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3efcc8c-03f2-4241-b9e8-60b61fd79053",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# data.query(f\"media_id=={inverse_mapping[36474]}\")\n",
    "\n",
    "# data.query(f\"user_id==[88,11]\").media_id_mapped.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d48e3c5-fa38-4d4e-834b-31c0f6325d0c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sorted_predicted_ids[:30]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}